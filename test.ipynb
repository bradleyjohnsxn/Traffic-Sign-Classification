{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ce51fbc-0614-414c-becb-8120a39d9bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn.functional import interpolate\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "from tqdm import trange\n",
    "import sklearn.metrics as met\n",
    "from sklearn.preprocessing import MinMaxScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f7316da-c895-4514-ac32-9bdcf792caae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ----------------------------------- MODEL CLASS AND FUNCTIONS ----------------------------------- ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f681d4a-41bc-43e1-8df5-383bde36711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- MODEL CLASS ------------- #\n",
    "\n",
    "# define cnn class\n",
    "class cnn(nn.Module):\n",
    "    def __init__(self, numChannels, classes):\n",
    "        # call the parent constructor\n",
    "        super(cnn, self).__init__()\n",
    "        # initialize first set of CONV => POOL => RELU layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=numChannels, out_channels=200,\n",
    "            kernel_size=(5,5), stride=2, padding=1)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # initialize second set of CONV => POOL => RELU layers\n",
    "        self.dropout1 = nn.Dropout(0.6)\n",
    "        self.conv2 = nn.Conv2d(in_channels=200, out_channels=650,\n",
    "            kernel_size=(5,5), padding=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "                               \n",
    "        # initialize final set of CONV => POOL => RELU layers\n",
    "        self.dropout2 = nn.Dropout(0.6)\n",
    "        self.conv3 = nn.Conv2d(in_channels=650, out_channels=350,\n",
    "            kernel_size=(5,5), padding=1)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=3)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "                               \n",
    "        # initialize our softmax classifier\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(in_features=1400, out_features=128)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "            \n",
    "        self.dropout4 = nn.Dropout(0.6)\n",
    "        self.fc3 = nn.Linear(in_features=128, out_features=classes)\n",
    "        self.logSoftmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # pass the input through our first set of CONV => RELU =>\n",
    "        # POOL layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        # pass the output from the previous layer through the second\n",
    "        # set of CONV => RELU => POOL layers\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)                       \n",
    "        \n",
    "        # through final CONV => RELU => POOL layer\n",
    "        x = self.dropout2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.maxpool3(x)\n",
    "        \n",
    "        # pass the output to our softmax classifier to get our output\n",
    "        # predictions\n",
    "        m = nn.Flatten()\n",
    "        x = m(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.dropout4(x)\n",
    "        x = self.fc3(x)\n",
    "        output = self.logSoftmax(x)\n",
    "        # return the output predictions\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3942f69-6a4e-4ec2-9874-0c25173bdc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- FUNCTIONS ------------- #\n",
    "\n",
    "# function to reshape images\n",
    "def change_dataset(changed, dataset, BS):\n",
    "    ind = min(len(dataset),BS)\n",
    "    X = np.zeros((ind,300,300,3))\n",
    "    \n",
    "    if ind != len(dataset):\n",
    "        X = dataset[:ind]\n",
    "        X = X.reshape((ind,300,300,3))\n",
    "        res = np.zeros((X.shape[0],3,300,300))\n",
    "        for i in range(X.shape[0]):\n",
    "            res[i] = np.moveaxis(X[i],-1,0)\n",
    "        res = interpolate(torch.tensor(res),size=(175,175),mode='bicubic',align_corners=False)\n",
    "        \n",
    "        if len(changed) == 1:\n",
    "            changed = np.vstack([changed,np.array(res)])\n",
    "            changed = changed [1:]\n",
    "        else:\n",
    "            changed = np.vstack([changed,np.array(res)])\n",
    "        dataset = dataset[ind:]\n",
    "        \n",
    "    else:\n",
    "        X = dataset\n",
    "        X = X.reshape((ind,300,300,3))\n",
    "        res = np.zeros((X.shape[0],3,300,300))\n",
    "        for i in range(X.shape[0]):\n",
    "            res[i] = np.moveaxis(X[i],-1,0)\n",
    "        res = interpolate(torch.tensor(res),size=(175,175),mode='bicubic',align_corners=False)\n",
    "        changed = np.vstack([changed,np.array(res)])\n",
    "        dataset = np.array([])\n",
    "    return changed, dataset\n",
    "\n",
    "# testing function\n",
    "def test(model,X_test,t_test,device='cpu',BS=128):\n",
    "    model.to(device)\n",
    "    # prep data\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    t_test = torch.tensor(t_test, dtype=torch.long)\n",
    "    test_data = TensorDataset(X_test, t_test)\n",
    "\n",
    "    X_test = []\n",
    "    loader_test = DataLoader(test_data, batch_size=BS)\n",
    "    \n",
    "    # test\n",
    "    y_preds = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, (x,y) in enumerate(loader_test):\n",
    "            preds = []\n",
    "            x=x.to(device)\n",
    "            y=y.to(device)\n",
    "            # make the predictions\n",
    "            pred = model(x)\n",
    "            preds += pred.argmax(1).cpu()\n",
    "            y_preds += preds\n",
    "            \n",
    "            \n",
    "    # compute accuracy and confusion matrix\n",
    "    test_acc = np.sum(np.array(y_preds)==np.array(t_test))/len(t_test)\n",
    "        \n",
    "    model.to(torch.device('cpu'))\n",
    "    return test_acc, y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7a64b33-1704-4c44-a93b-a91614ca7a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ----------------------------------- MAIN ----------------------------------- ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f133f76-3141-4a9f-b093-0f107575de0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- DATA PATHS ------------- #\n",
    "test_data_path = '../share/data_train.npy'\n",
    "test_labels_path = '../share/labels_train.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da68ea60-71cd-47ac-a2a7-116cbd5bf447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. dataset.shape, labels.shape: ((270000, 6195), (6195,))\n",
      "2. X_test.shape, t_test.shape: ((6195, 3, 175, 175), (6195,))\n",
      "3. X_test.shape, t_test.shape: ((6195, 3, 175, 175), (6195,))\n"
     ]
    }
   ],
   "source": [
    "# ----------- PREPARING DATA ------------- #\n",
    "# loading Data\n",
    "dataset = np.load(test_data_path)\n",
    "t_test = np.load(test_labels_path)\n",
    "print(f'1. dataset.shape, labels.shape: {dataset.shape, t_test.shape}')\n",
    "\n",
    "# fixing mislabeled data\n",
    "location = [880, 165, 558, 2396, 3198, 3715, 3734, 3824, 4412, 5238, 38, 2303, 3127, 3467, 3515, 5404, 6178, 248, 827, 1139, 1799, 2491, 2546, 4533, 6024, 103, 392, 846, 913, 1487, 2971, 3234, 3851, 4008, 4405, 4442, 4952, 5348, 204, 272, 297, 1177, 1198, 1326, 1655, 2156, 2690, 2864, 3450, 5095, 5111, 5186, 5243, 5785, 6106,387, 3973, 5112, 5331, 5002, 5263, 6046, 1843, 2941, 3419, 4158, 4166, 4369, 4980, 689, 973, 3066, 3028, 4905, 5107, 5708, 5817, 357, 368, 1065, 2093, 3229, 3341, 4469, 5257, 5711]\n",
    "true_label = [6, 4, 7, 9, 5, 6, 3, 8, 2, 0, 5, 1, 4, 6, 3, 7, 9, 2, 7, 2, 8, 5, 1, 0, 6, 5, 2, 5, 6, 0, 5, 5, 5, 8, 5, 2, 5, 1, 4, 4, 4, 1, 4, 7, 0, 4, 4, 4, 9, 4, 4, 4, 8, 4, 0, 8, 3, 5, 2, 5, 0, 4, 6, 8, 0, 6, 9, 5, 2, 0, 3, 6, 7, 2, 5, 7, 1, 2, 7, 0, 5, 8,3, 1, 6, 8]\n",
    "\n",
    "for k in range(len(location)):\n",
    "    t_test[location[k]] = true_label[k]\n",
    "\n",
    "# downsample data\n",
    "dataset = dataset.T\n",
    "X_test = np.zeros((1,3,175,175))\n",
    "while len(dataset) != 0:\n",
    "    X_test, dataset = change_dataset(X_test,dataset,64)\n",
    "print(f'2. X_test.shape, t_test.shape: {X_test.shape, t_test.shape}')\n",
    "\n",
    "# min-max scaling\n",
    "X_test = X_test.reshape((len(X_test), 3*175*175))\n",
    "mms = MinMaxScaler()\n",
    "X_test = mms.fit_transform(X_test)\n",
    "X_test = X_test.reshape((len(X_test),3,175,175))\n",
    "print(f'3. X_test.shape, t_test.shape: {X_test.shape, t_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "360319d4-add8-496d-8be2-a102aee9c698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------- SET UP DEVICE AND MODEL ------------- #\n",
    "\n",
    "# setup device to be cuda if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# initialize the model\n",
    "model = cnn(numChannels=3,classes=10)\n",
    "\n",
    "# load model\n",
    "model.load_state_dict(torch.load('maib_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eb09cb1-59c5-4050-a08d-15876e9e1c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9937046004842615\n",
      "\n",
      "Test confusion matrix:\n",
      " [[622   1   1   0   0   1   0   0   0   0]\n",
      " [  0 608   0   0   0   2   0   0   0   0]\n",
      " [  1   1 613   0   1   1   1   0   0   0]\n",
      " [  0   0   0 612   1   0   0   0   0   0]\n",
      " [  0   0   0   0 613   1   0   4   6   1]\n",
      " [  0   0   0   0   0 616   0   0   0   2]\n",
      " [  2   1   0   0   0   0 617   1   0   1]\n",
      " [  0   0   0   0   3   0   0 620   0   0]\n",
      " [  0   0   0   1   0   0   0   0 626   0]\n",
      " [  0   0   0   0   0   3   1   1   0 609]]\n"
     ]
    }
   ],
   "source": [
    "# ----------- TESTING ------------- #\n",
    "\n",
    "# testing\n",
    "acc, y_preds = test(model,X_test,t_test,device)\n",
    "\n",
    "# confustion matrix for test set.\n",
    "con_mat = met.confusion_matrix(t_test, y_preds)\n",
    "\n",
    "print(f'Test accuracy: {acc}\\n\\nTest confusion matrix:\\n {con_mat}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NGC-PyTorch-1.9",
   "language": "python",
   "name": "ngc-pytorch-1.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
